{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d6fc572-b0af-4bdb-acd4-d8d281a03c03",
   "metadata": {},
   "source": [
    "# Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb14faa-41d3-4c22-b552-c8d7115ee4ea",
   "metadata": {},
   "source": [
    "- Bayes' theorem, named after the Reverend Thomas Bayes, is a fundamental theorem in probability theory. It describes the probability of an event based on prior knowledge or conditions that might be related to the event. \n",
    "\n",
    "Mathematically, Bayes' theorem is expressed as:\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)} \\]\n",
    "\n",
    "where:\n",
    "- \\( P(A|B) \\) is the probability of event A occurring given that event B has occurred.\n",
    "- \\( P(B|A) \\) is the probability of event B occurring given that event A has occurred.\n",
    "- \\( P(A) \\) and \\( P(B) \\) are the probabilities of events A and B occurring, respectively.\n",
    "\n",
    "- Bayes' theorem is commonly used in statistics, machine learning, and various fields to update beliefs or probabilities based on new evidence or information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a171e9-612f-4ea9-97d4-4f529bb62d95",
   "metadata": {},
   "source": [
    "# Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f298b7-90a1-4165-ba55-340160bcd985",
   "metadata": {},
   "source": [
    "- The formula for Bayes' theorem is:\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)} \\]\n",
    "\n",
    "where:\n",
    "- \\( P(A|B) \\) is the probability of event A occurring given that event B has occurred.\n",
    "- \\( P(B|A) \\) is the probability of event B occurring given that event A has occurred.\n",
    "- \\( P(A) \\) and \\( P(B) \\) are the probabilities of events A and B occurring, respectively.\n",
    "\n",
    "- Bayes' theorem is a fundamental theorem in probability theory that describes how to update beliefs or probabilities based on new evidence or information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f97861e-4c0c-4717-b9f5-f40b2e115d14",
   "metadata": {},
   "source": [
    "# Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca5222-667f-46d9-aab3-472a34615057",
   "metadata": {},
   "source": [
    "- Bayes' theorem is used in a variety of practical applications across different fields. Some common uses include:\n",
    "\n",
    "1. **Medical Diagnosis:** In medical diagnosis, Bayes' theorem can be used to calculate the probability that a patient has a particular disease given their symptoms and the prevalence of the disease in the population.\n",
    "\n",
    "2. **Spam Filtering:** In spam filtering, Bayes' theorem is used to classify emails as spam or not spam based on the probability of certain words or phrases appearing in spam emails versus legitimate emails.\n",
    "\n",
    "3. **Machine Learning:** In machine learning, Bayes' theorem is used in Bayesian inference to update the probability of a hypothesis based on new evidence. It is also used in Bayesian networks for probabilistic reasoning.\n",
    "\n",
    "4. **Risk Assessment:** Bayes' theorem is used in risk assessment to calculate the probability of an event occurring based on prior knowledge and new information. This is particularly useful in fields such as finance and insurance.\n",
    "\n",
    "5. **Quality Control:** In quality control, Bayes' theorem can be used to update the probability that a product meets certain quality standards based on the results of quality tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1facdf-0bab-45f5-bd72-74171bd95b36",
   "metadata": {},
   "source": [
    "# Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bfe4e6-3163-45ca-a013-c559350847e4",
   "metadata": {},
   "source": [
    "- Bayes' theorem is closely related to conditional probability. Conditional probability is the probability of an event occurring given that another event has already occurred. Bayes' theorem provides a way to calculate conditional probabilities using prior probabilities.\n",
    "\n",
    "The relationship between Bayes' theorem and conditional probability can be seen in the formula for Bayes' theorem:\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)} \\]\n",
    "\n",
    "- In this formula, \\( P(A|B) \\) is the conditional probability of event A given event B, \\( P(B|A) \\) is the conditional probability of event B given event A, \\( P(A) \\) is the prior probability of event A, and \\( P(B) \\) is the prior probability of event B.\n",
    "\n",
    "- Bayes' theorem allows us to calculate the conditional probability of event A given event B using the prior probabilities of events A and B, as well as the conditional probability of event B given event A. It provides a way to update our beliefs about the probability of an event based on new evidence or information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7743b977-ac03-4074-a608-d1333d355be9",
   "metadata": {},
   "source": [
    "# Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba27b9b8-c739-42b2-9153-8cf7913f5d5b",
   "metadata": {},
   "source": [
    "- Choosing the right type of Naive Bayes classifier depends on the characteristics of your data and the assumptions you're willing to make about the independence of features. Here are the common types of Naive Bayes classifiers and when to use them:\n",
    "\n",
    "1. **Gaussian Naive Bayes:** This classifier assumes that the features follow a normal distribution. It is suitable for continuous features.\n",
    "\n",
    "2. **Multinomial Naive Bayes:** This classifier is suitable for discrete features, such as word counts in text classification. It's commonly used in document classification tasks.\n",
    "\n",
    "3. **Bernoulli Naive Bayes:** This classifier is similar to the multinomial Naive Bayes but is used for features that are binary-valued (e.g., presence or absence of a feature).\n",
    "\n",
    "To choose the right classifier, consider the following:\n",
    "\n",
    "- **Nature of Features:** If your features are continuous, Gaussian Naive Bayes might be suitable. If they are discrete and represent counts (like word counts), consider multinomial or Bernoulli Naive Bayes.\n",
    "  \n",
    "- **Assumptions:** Naive Bayes assumes that features are independent, which may not always hold true. However, it can still perform well in practice even if this assumption is violated, especially with a large dataset.\n",
    "\n",
    "- **Size of Dataset:** Naive Bayes can perform well with small datasets and is relatively less prone to overfitting compared to more complex models like decision trees or neural networks.\n",
    "\n",
    "- **Scalability:** Naive Bayes is computationally efficient and scales well with large datasets and high-dimensional feature spaces.\n",
    "\n",
    "- **Previous Knowledge:** If you have prior knowledge about the distribution of your data, you can choose the corresponding Naive Bayes variant that best aligns with that knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce4082-982d-401b-b2f2-45e6feac7b42",
   "metadata": {},
   "source": [
    "# Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive \n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of \n",
    "each feature value for each class:\n",
    "\n",
    "Class\t X1=1 X1=2 \tX1=3 \tX2=1 \tX2=2 \tX2=3\t X2=4\n",
    "\n",
    " A\t     3\t   3\t  4\t     4\t     3\t     3\t      3\n",
    "\n",
    " B\t     2\t   2\t  1\t     2\t     2\t     2\t      3\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance \n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc44c20-27fa-4dc2-b572-2bbc8b7600e0",
   "metadata": {},
   "source": [
    "- To classify the new instance with features X1 = 3 and X2 = 4 using Naive Bayes, we need to calculate the conditional probabilities of each class given these feature values. Since the prior probabilities for each class are equal, we can focus on calculating the likelihoods.\n",
    "\n",
    "- The likelihood of a class given the features is calculated as the product of the conditional probabilities of each feature value given the class. Since Naive Bayes assumes independence between features, we can calculate the conditional probabilities for each feature independently.\n",
    "\n",
    "For class A:\n",
    "\\[ P(X1=3|A) = \\frac{4}{13} \\]\n",
    "\\[ P(X2=4|A) = \\frac{3}{13} \\]\n",
    "\n",
    "Likelihood of class A: \\( P(A|X1=3, X2=4) = P(X1=3|A) \\times P(X2=4|A) = \\frac{4}{13} \\times \\frac{3}{13} \\)\n",
    "\n",
    "For class B:\n",
    "\\[ P(X1=3|B) = \\frac{1}{7} \\]\n",
    "\\[ P(X2=4|B) = \\frac{1}{7} \\]\n",
    "\n",
    "Likelihood of class B: \\( P(B|X1=3, X2=4) = P(X1=3|B) \\times P(X2=4|B) = \\frac{1}{7} \\times \\frac{1}{7} \\)\n",
    "\n",
    "- Since the prior probabilities are equal, we don't need to calculate them explicitly. We can compare the likelihoods for each class and choose the class with the highest likelihood.\n",
    "\n",
    "\\[ P(A|X1=3, X2=4) \\propto P(X1=3|A) \\times P(X2=4|A) = \\frac{4}{13} \\times \\frac{3}{13} \\]\n",
    "\n",
    "\\[ P(B|X1=3, X2=4) \\propto P(X1=3|B) \\times P(X2=4|B) = \\frac{1}{7} \\times \\frac{1}{7} \\]\n",
    "\n",
    "- Comparing the two likelihoods, we see that \\( P(A|X1=3, X2=4) > P(B|X1=3, X2=4) \\). Therefore, Naive Bayes would predict the new instance to belong to class A."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
